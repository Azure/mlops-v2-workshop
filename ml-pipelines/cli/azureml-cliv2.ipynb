{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "For this workshop, you need:\n",
        "\n",
        "* An Azure Machine Learning workspace. \n",
        "* The Azure Machine Learning CLI v2 installed.\n",
        "\n",
        "To install the CLI you can either,\n",
        "\n",
        "Create a compute instance, which already has installed the latest AzureML CLI and is pre-configured for ML workflows.\n",
        "\n",
        "Use the followings commands to install Azure ML CLI v2:\n",
        "\n",
        "```bash\n",
        "az extension add --name ml\n",
        "az login --identity\n",
        "```\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az extension add --name ml\r\n",
        "!az login --identity"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## (Optional) 1. Create Managed Compute\n",
        "\n",
        "A compute is a designated compute resource where you run your job or host your endpoint. Azure Machine learning supports the following types of compute:\n",
        "\n",
        "- **Compute instance** - a fully configured and managed development environment in the cloud. You can use the instance as a training or inference compute for development and testing. It's similar to a virtual machine on the cloud.\n",
        "\n",
        "- **Compute cluster** - a managed-compute infrastructure that allows you to easily create a cluster of CPU or GPU compute nodes in the cloud.\n",
        "\n",
        "- **Kubernetes cluster** - used to deploy trained machine learning models to Azure Kubernetes Service. You can create an Azure Kubernetes Service (AKS) cluster from your Azure ML workspace, or attach an existing AKS cluster.\n",
        "\n",
        "- **Attached compute** - You can attach your own compute resources to your workspace and use them for training and inference.\n",
        "\n",
        "You can create a compute using the Studio, the cli and the sdk.\n",
        "\n",
        "<hr>\n",
        "\n",
        "We can create a **compute instance** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_compute_instance.png\" width = \"700px\" alt=\"Create Compute Instance cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "We can create a **compute cluster** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_compute_cluster.png\" width = \"700px\" alt=\"Create Compute Instance cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "\n",
        "Let's create a managed compute cluster for the training workload."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` python\n",
        "# Create train job compute cluster\n",
        "!az ml compute create --file train/compute.yml\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## 2. Register Data Asset\n",
        "\n",
        "**Datastore** - Azure Machine Learning Datastores securely keep the connection information to your data storage on Azure, so you don't have to code it in your scripts.\n",
        "\n",
        "An Azure Machine Learning datastore is a **reference** to an **existing** storage account on Azure. The benefits of creating and using a datastore are:\n",
        "* A common and easy-to-use API to interact with different storage type. \n",
        "* Easier to discover useful datastores when working as a team.\n",
        "* When using credential-based access (service principal/SAS/key), the connection information is secured so you don't have to code it in your scripts.\n",
        "\n",
        "Supported Data Resources: \n",
        "\n",
        "* Azure Storage blob container\n",
        "* Azure Storage file share\n",
        "* Azure Data Lake Gen 1\n",
        "* Azure Data Lake Gen 2\n",
        "\n",
        "\n",
        "It is not a requirement to use Azure Machine Learning datastores - you can use storage URIs directly assuming you have access to the underlying data.\n",
        "\n",
        "You can create a datastore using the Studio, the cli and the sdk.\n",
        "\n",
        "<hr>\n",
        "\n",
        "We can create a **datastore** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_datastore.png\" width = \"700px\" alt=\"Create Datastore cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "**Data asset** - Create data assets in your workspace to share with team members, version, and track data lineage.\n",
        "\n",
        "By creating a data asset, you create a reference to the data source location, along with a copy of its metadata. \n",
        "\n",
        "The benefits of creating data assets are:\n",
        "\n",
        "* You can **share and reuse data** with other members of the team such that they do not need to remember file locations.\n",
        "* You can **seamlessly access data** during model training (on any supported compute type) without worrying about connection strings or data paths.\n",
        "* You can **version** the data.\n",
        "\n",
        "<hr>\n",
        "\n",
        "We can create a **data asset** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_data_asset.png\" width = \"700px\" alt=\"Create Data Asset cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register data asset \n",
        "!az ml data create --file train/data.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1671207553070
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Register Train Environment\n",
        "\n",
        "Azure Machine Learning environments define the execution environments for your **jobs** or **deployments** and encapsulate the dependencies for your code. \n",
        "\n",
        "Azure ML uses the environment specification to create the Docker container that your **training** or **scoring code** runs in on the specified compute target.\n",
        "\n",
        "Create an environment from a\n",
        "* conda specification\n",
        "* Docker image\n",
        "* Docker build context\n",
        "\n",
        "There are two types of environments in Azure ML: **curated** and **custom environments**. Curated environments are predefined environments containing popular ML frameworks and tooling. Custom environments are user-defined.\n",
        "\n",
        "<hr>\n",
        "\n",
        "We can register an **environment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_environment.png\" width = \"700px\" alt=\"Create Environment cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register train environment \n",
        "!az ml environment create --file train/environment.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create Pipeline Job\n",
        "\n",
        "**AML Job**:\n",
        "\n",
        "Azure ML provides several ways to train your models, from code-first solutions to low-code solutions:\n",
        "\n",
        "* Azure ML supports script files in python, R, Java, Julia or C#. All you need to learn is YAML format and command lines to use Azure ML.\n",
        "\n",
        "* Distributed Training: AML supports integrations with popular frameworks, PyTorch and TensorFlow. Both frameworks employ data parallelism & model parallelism for distributed training.\n",
        "\n",
        "* Automated ML - Train models without extensive data science or programming knowledge.\n",
        "\n",
        "* Designer - drag and drop web-based UI.\n",
        "\n",
        "<hr>\n",
        "\n",
        "We can submit a **job** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_job.png\" width = \"700px\" alt=\"Create Job cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "<br>\n",
        "    \n",
        "**AML Pipelines**:\n",
        "\n",
        "An AML pipeline is an independently executable workflow of a complete machine learning task. It helps standardizing the best practices of producing a machine learning model: The core of a machine learning pipeline is to split a complete machine learning task into a multistep workflow. Each step is a manageable component that can be developed, optimized, configured, and automated individually. \n",
        "\n",
        "<hr>\n",
        "\n",
        "We can submit a **pipeline job** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_pipeline.png\" width = \"700px\" alt=\"Create Pipeline cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline job\n",
        "!az ml job create --file train/pipeline.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Online Endpoint\n",
        "\n",
        "Online endpoints are endpoints that are used for online (real-time) inferencing. They receive data from clients and can send responses back in real time.\n",
        "\n",
        "An **endpoint** is an HTTPS endpoint that clients can call to receive the inferencing (scoring) output of a trained model. It provides:\n",
        "* Authentication using \"key & token\" based auth\n",
        "* SSL termination\n",
        "* A stable scoring URI (endpoint-name.region.inference.ml.azure.com)\n",
        "\n",
        "A **deployment** is a set of resources required for hosting the model that does the actual inferencing.\n",
        "A single endpoint can contain multiple deployments.\n",
        "\n",
        "Features of the managed online endpoint:\n",
        "\n",
        "* **Test and deploy locally** for faster debugging\n",
        "* Traffic to one deployment can also be **mirrored** (copied) to another deployment.\n",
        "* **Application Insights integration**\n",
        "* Security\n",
        "* Authentication: Key and Azure ML Tokens\n",
        "* Automatic Autoscaling\n",
        "* Visual Studio Code debugging\n",
        "\n",
        "**blue-green deployment**: An approach where a new version of a web service is introduced to production by deploying it to a small subset of users/requests before deploying it fully.\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/endpoint_concept.png\" width = \"500px\" alt=\"Online Endpoint Concept cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Online Endpoint\n",
        "\n",
        "We can create an **online endpoint** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_online_endpoint.png\" width = \"700px\" alt=\"Create Online Endpoint cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create online endpoint\n",
        "!az ml online-endpoint create --file deploy/online/online-endpoint.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Online Deployment\n",
        "\n",
        "To create a deployment to online endpoint, you need to specify the following elements:\n",
        "\n",
        "* Model files (or specify a registered model in your workspace)\n",
        "* Scoring script - code needed to do scoring/inferencing\n",
        "* Environment - a Docker image with Conda dependencies, or a dockerfile\n",
        "* Compute instance & scale settings\n",
        "\n",
        "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated.\n",
        "\n",
        "We can create an **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_online_deployment.png\" width = \"700px\" alt=\"Create Online Deployment cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create online deployment\n",
        "!az ml online-deployment create --file deploy/online/online-deployment.yml "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Allocate Traffic"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# allocate traffic\n",
        "!az ml online-endpoint update --name taxi-online-endpoint-en --traffic blue=100"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Invoke and Test Endpoint\n",
        "\n",
        "We can invoke the **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/invoke_online_endpoint.png\" width = \"700px\" alt=\"Invoke online endpoint cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke and test endpoint\n",
        "!az ml online-endpoint invoke --name taxi-online-endpoint-en --request-file ../../data/taxi-request.json"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Batch Endpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Batch Compute Cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create compute cluster to be used by batch cluster\n",
        "!az ml compute create -n batch-cluster --type amlcompute --min-instances 0 --max-instances 3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Batch Endpoint\n",
        "\n",
        "We can create the **batch endpoint** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_batch_endpoint.png\" width = \"700px\" alt=\"Create batch endpoint cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create batch endpoint\n",
        "!az ml batch-endpoint create --file deploy/batch/batch-endpoint.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create Batch Deployment\n",
        "\n",
        "We can create the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_batch_deployment.png\" width = \"700px\" alt=\"Create batch deployment cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create batch deployment\n",
        "!az ml batch-deployment create --file deploy/batch/batch-deployment.yml --set-default"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Invoke and Test Endpoint\n",
        "\n",
        "We can invoke the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/invoke_batch_deployment.png\" width = \"700px\" alt=\"Invoke batch deployment cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke and test endpoint\n",
        "!az ml batch-endpoint invoke --name taxi-batch-endpoint --input ../../data/taxi-batch.csv --input-type uri_file"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For this workshop, you need:\n",
        "\n",
        "* An Azure Machine Learning workspace. \n",
        "* The Azure Machine Learning Python SDK v2 installed. \n",
        "\n",
        "To install the SDK you can either,\n",
        "\n",
        "Create a compute instance, which already has installed the latest AzureML Python SDK and is pre-configured for ML workflows.\n",
        "\n",
        "Use the followings commands to install Azure ML Python SDK v2:\n",
        "\n",
        "```bash\n",
        "pip install azure-ai-ml --upgrade\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to ML Client"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To connect to a workspace, you need to provide a subscription, resource group and workspace name. These details are used in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace.\n",
        "\n",
        "In the following example, the default Azure authentication is used along with the default workspace configuration or from any `config.json` file you might have copied into the folders structure. If no `config.json` is found, then you need to manually introduce the subscription_id, resource_group and workspace when creating `MLClient`.\n",
        "\n",
        "```python\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AzureML workspace\n",
        "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "    resource_group = \"<RESOURCE_GROUP>\"\n",
        "    workspace = \"<AZUREML_WORKSPACE_NAME>\"\n",
        "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
        "```\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Retrieve details of Azure ML workspace from environment variables of your Compute Instance\n",
        "subscription_id = re.search(\"subscriptions/(.*)/resourceGroups\", os.environ[\"MLFLOW_TRACKING_URI\"]).group(\n",
        "    1\n",
        ")  # Extract Azure Subcription ID from MLFlow Tracking URI\n",
        "resource_group = os.environ[\"CI_RESOURCE_GROUP\"]\n",
        "workspace_name = os.environ[\"CI_WORKSPACE\"]\n",
        "\n",
        "# Connect to Azure ML workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682556220056
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Online Endpoint\n",
        "\n",
        "Online endpoints are endpoints that are used for online (real-time) inferencing. They receive data from clients and can send responses back in real time.\n",
        "\n",
        "An **endpoint** is an HTTPS endpoint that clients can call to receive the inferencing (scoring) output of a trained model. It provides:\n",
        "* Authentication using \"key & token\" based auth\n",
        "* SSL termination\n",
        "* A stable scoring URI (endpoint-name.region.inference.ml.azure.com)\n",
        "\n",
        "A **deployment** is a set of resources required for hosting the model that does the actual inferencing.\n",
        "A single endpoint can contain multiple deployments.\n",
        "\n",
        "Features of the managed online endpoint:\n",
        "\n",
        "* **Test and deploy locally** for faster debugging\n",
        "* Traffic to one deployment can also be **mirrored** (copied) to another deployment.\n",
        "* **Application Insights integration**\n",
        "* Security\n",
        "* Authentication: Key and Azure ML Tokens\n",
        "* Automatic Autoscaling\n",
        "* Visual Studio Code debugging\n",
        "\n",
        "**blue-green deployment**: An approach where a new version of a web service is introduced to production by deploying it to a small subset of users/requests before deploying it fully.\n",
        "\n",
        "<center>\n",
        "<img src=\"../../../imgs/concept_online_endpoint.png\" width = \"500px\" alt=\"Online Endpoint Concept cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Online Endpoint\n",
        "\n",
        "We can create an **online endpoint** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../../imgs/create_online_endpoint.png\" width = \"700px\" alt=\"Create Online Endpoint cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "\n",
        "# create an online endpoint\n",
        "online_endpoint = ManagedOnlineEndpoint(\n",
        "    name=### TO DO ###, \n",
        "    description=### TO DO ###,\n",
        ")\n",
        "ml_client.online_endpoints.begin_create_or_update(\n",
        "    online_endpoint,   \n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1668240520864
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Online Deployment\n",
        "\n",
        "To create a deployment to online endpoint, you need to specify the following elements:\n",
        "\n",
        "* Model files (or specify a registered model in your workspace)\n",
        "* Scoring script - code needed to do scoring/inferencing\n",
        "* Environment - a Docker image with Conda dependencies, or a dockerfile\n",
        "* Compute instance & scale settings\n",
        "\n",
        "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated.\n",
        "\n",
        "We can create an **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../../imgs/create_online_deployment.png\" width = \"700px\" alt=\"Create Online Deployment cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create online deployment\r\n",
        "from azure.ai.ml.entities import ManagedOnlineDeployment, Model, Environment\r\n",
        "from azure.ai.ml.entities import (\r\n",
        "    Environment,\r\n",
        "    CodeConfiguration,\r\n",
        ")\r\n",
        "\r\n",
        "env = Environment(\r\n",
        "    conda_file=\"../../../data-science/environment/deploy-online-conda.yml\",\r\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\r\n",
        ")\r\n",
        "\r\n",
        "blue_deployment = ManagedOnlineDeployment(\r\n",
        "    name=### TO DO ###,\r\n",
        "    endpoint_name=### TO DO ###,\r\n",
        "    model=### TO DO ###,\r\n",
        "    environment=### TO DO ###,\r\n",
        "    code_configuration=CodeConfiguration(\r\n",
        "        code=\"../../../data-science/src/score\", scoring_script=### TO DO ###\r\n",
        "    ),\r\n",
        "    instance_type=\"Standard_DS2_v2\",\r\n",
        "    instance_count=1,\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.online_deployments.begin_create_or_update(\r\n",
        "    deployment=blue_deployment\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Allocate Traffic"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# allocate traffic\n",
        "# new deployment takes 100 traffic\n",
        "online_endpoint.traffic = {### TO DO ###: ### TO DO ###}\n",
        "ml_client.begin_create_or_update(online_endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668246669855
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Invoke and Test Endpoint\n",
        "\n",
        "We can invoke the **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../../imgs/invoke_online_endpoint.png\" width = \"700px\" alt=\"Invoke online endpoint cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke and test endpoint\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=### TO DO ###,\n",
        "    request_file=\"../../../data/taxi-request.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668246829854
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}